{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import relevant libraries and creates access to library seen in class\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #Visualization\nfrom scipy.sparse import * # COO, CSR and CSC matrices\n\n\n# Access to professor library\nfrom os import sys\n\npackage_paths = [\n    '../input/mauriziofd/',\n]\n\nfor pth in package_paths:\n    sys.path.append(pth)\n    \nfrom Recommenders.Similarity.Compute_Similarity_Python import Compute_Similarity_Python","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-04T20:08:42.589756Z","iopub.execute_input":"2022-01-04T20:08:42.590045Z","iopub.status.idle":"2022-01-04T20:08:42.760025Z","shell.execute_reply.started":"2022-01-04T20:08:42.590017Z","shell.execute_reply":"2022-01-04T20:08:42.759154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read data for the URM and ICM\nURM_df= pd.read_csv('../input/recommender-system-2021-challenge-polimi/data_train.csv', dtype={0:int, 1:int, 2:float})\ngenre_matrix = pd.read_csv('../input/recommender-system-2021-challenge-polimi/data_ICM_genre.csv', dtype={0:int, 1:int, 2:int})\ntarget_users = pd.read_csv('../input/recommender-system-2021-challenge-polimi/data_target_users_test.csv', dtype={0:int})\nsubgenre_matrix = pd.read_csv('../input/recommender-system-2021-challenge-polimi/data_ICM_subgenre.csv', dtype={0:int, 1:int, 2:int})\nchannel_matrix = pd.read_csv('../input/recommender-system-2021-challenge-polimi/data_ICM_channel.csv', dtype={0:int, 1:int, 2:int})\n\ntarget_users.columns = ['user_id']\nURM_df.columns = ['user', 'item', 'interaction']\ngenre_matrix.columns = ['item', 'genre', 'hasgenre']\nsubgenre_matrix.columns = ['item', 'subgenre', 'hassubgenre']\nchannel_matrix.columns = ['item', 'channel', 'onchannel']\n\n# Merge datasets into the ICM\ngenre_subgenre_ICM = pd.merge(genre_matrix, subgenre_matrix, on='item')\nICM_df = pd.merge(genre_subgenre_ICM, channel_matrix, on='item')\n\nICM_df.pop('hasgenre')\nICM_df.pop('hassubgenre')\nICM_df = ICM_df.rename({'onchannel':'data'}, axis='columns')\n\n# Calculates number of genres, subgenres and channels\n\n# Creates csc matrix from dataframe\nURM_all = coo_matrix((URM_df['interaction'].values, (URM_df['user'].values, URM_df['item'].values)))\nURM_csr = URM_all.tocsr()\ngenre_coo = coo_matrix((genre_matrix['hasgenre'].values, (genre_matrix['item'].values, genre_matrix['genre'].values)))\ngenre_csc = genre_coo.tocsc()\nsubgenre_coo = coo_matrix((subgenre_matrix['hassubgenre'].values, (subgenre_matrix['item'].values, subgenre_matrix['subgenre'].values)))\nsubgenre_csc = subgenre_coo.tocsc()\nchannel_coo = coo_matrix((channel_matrix['onchannel'].values, (channel_matrix['item'].values, channel_matrix['channel'].values)))\nchannel_csc = channel_coo.tocsc()\nchannel_csr = channel_coo.tocsr()\n\n# Quite inefficient, maybe there's a unique approach from exercise sessions\nn_of_genres = genre_coo.shape[1]\n\nn_of_subgenres = subgenre_coo.shape[1]\n\nn_of_channels = channel_coo.shape[1]\n\nprint(n_of_genres, n_of_subgenres, n_of_channels)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T20:08:44.905677Z","iopub.execute_input":"2022-01-04T20:08:44.906399Z","iopub.status.idle":"2022-01-04T20:08:47.669186Z","shell.execute_reply.started":"2022-01-04T20:08:44.90636Z","shell.execute_reply":"2022-01-04T20:08:47.668194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split in training and validation to assess how good the predictions will be at test time\nfrom Evaluation.Evaluator import EvaluatorHoldout\nfrom Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n\nURM_train, URM_validation = split_train_in_two_percentage_global_sample(URM_csr, train_percentage = 0.80)\n\nevaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])","metadata":{"execution":{"iopub.status.busy":"2022-01-04T20:08:47.670674Z","iopub.execute_input":"2022-01-04T20:08:47.670912Z","iopub.status.idle":"2022-01-04T20:09:02.286634Z","shell.execute_reply.started":"2022-01-04T20:08:47.670886Z","shell.execute_reply":"2022-01-04T20:09:02.285762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\nrecommender_ItemKNNCF = ItemKNNCFRecommender(URM_train)\n\nx_tick = [10, 50, 100, 200, 500]\nMAP_per_k = []\n\nfor topK in x_tick:\n    \n    recommender_ItemKNNCF.fit(shrink=0.0, topK=topK)\n    \n    result_df, _ = evaluator_validation.evaluateRecommender(recommender_ItemKNNCF)\n    \n    MAP_per_k.append(result_df.loc[10][\"MAP\"])\n    print(\"topK = {}, MAP = {}\".format(topK, result_df.loc[10][\"MAP\"]))\n\nplt.plot(x_tick, MAP_per_k)\nplt.ylabel('MAP')\nplt.xlabel('TopK')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-04T16:13:37.693012Z","iopub.execute_input":"2022-01-04T16:13:37.693944Z","iopub.status.idle":"2022-01-04T16:19:14.979016Z","shell.execute_reply.started":"2022-01-04T16:13:37.693901Z","shell.execute_reply":"2022-01-04T16:19:14.978098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shrink_tick = [0, 5, 10, 15, 20, 50, 100]\nMAP_per_shrinkage = []\n\nfor shrink in shrink_tick:\n    \n    recommender_ItemKNNCF.fit(shrink=shrink, topK=200)\n    \n    result_df, _ = evaluator_validation.evaluateRecommender(recommender_ItemKNNCF)\n    \n    MAP_per_shrinkage.append(result_df.loc[10][\"MAP\"])\n    print(\"shrink = {}, MAP = {}\".format(shrink, result_df.loc[10][\"MAP\"]))\nplt.plot(shrink_tick, MAP_per_shrinkage)\nplt.ylabel('MAP')\nplt.xlabel('Shrink')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T16:20:00.728609Z","iopub.execute_input":"2022-01-04T16:20:00.728903Z","iopub.status.idle":"2022-01-04T16:28:48.639875Z","shell.execute_reply.started":"2022-01-04T16:20:00.728874Z","shell.execute_reply":"2022-01-04T16:28:48.638894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from Recommenders.MatrixFactorization.PureSVDRecommender import PureSVDRecommender\n\npureSVD = PureSVDRecommender(URM_train)\n\nfactors_tick = [15, 20, 25, 30, 35,40]\nMAP_per_shrinkage = []\n\nfor factor in factors_tick:\n    \n    pureSVD.fit(num_factors=factor)\n    \n    result_df, _ = evaluator_validation.evaluateRecommender(pureSVD)\n    \n    MAP_per_shrinkage.append(result_df.loc[10][\"MAP\"])\n    print(\"latent factors = {}, MAP = {}\".format(factor, result_df.loc[10][\"MAP\"]))\n    \nplt.plot(factors_tick, MAP_per_shrinkage)\nplt.ylabel('MAP')\nplt.xlabel('Latent factors')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T17:05:01.080166Z","iopub.execute_input":"2022-01-04T17:05:01.080479Z","iopub.status.idle":"2022-01-04T17:06:28.280238Z","shell.execute_reply.started":"2022-01-04T17:05:01.080452Z","shell.execute_reply":"2022-01-04T17:06:28.279172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from Recommenders.KNN.UserKNNCFRecommender import UserKNNCFRecommender\nrecommender_userKNN = UserKNNCFRecommender(URM_train)\nrecommender_userKNN.fit(shrink=0, topK=300)\nresult_df, _ = evaluator_validation.evaluateRecommender(recommender_userKNN)\nprint(\"MAP = {}\".format(result_df.loc[10][\"MAP\"]))","metadata":{"execution":{"iopub.status.busy":"2022-01-04T16:08:01.114322Z","iopub.execute_input":"2022-01-04T16:08:01.114894Z","iopub.status.idle":"2022-01-04T16:08:57.50746Z","shell.execute_reply.started":"2022-01-04T16:08:01.114844Z","shell.execute_reply":"2022-01-04T16:08:57.506523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from Recommenders.BaseRecommender import BaseRecommender\n\nclass ScoresHybridRecommender(BaseRecommender):\n    \"\"\" ScoresHybridRecommender\n    Hybrid of two prediction scores R = R1*alpha + R2*(1-alpha)\n\n    \"\"\"\n\n    RECOMMENDER_NAME = \"ScoresHybridRecommender\"\n\n    def __init__(self, URM_train, recommender_1, recommender_2):\n        super(ScoresHybridRecommender, self).__init__(URM_train)\n\n        self.URM_train = sps.csr_matrix(URM_train)\n        self.recommender_1 = recommender_1\n        self.recommender_2 = recommender_2\n        \n        \n    def fit(self, alpha = 0.5):\n        self.alpha = alpha      \n\n\n    def _compute_item_score(self, user_id_array, items_to_compute):\n        \n        # In a simple extension this could be a loop over a list of pretrained recommender objects\n        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\n        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\n\n        item_weights = item_weights_1*self.alpha + item_weights_2*(1-self.alpha)\n\n        return item_weights","metadata":{"execution":{"iopub.status.busy":"2022-01-04T15:52:28.469434Z","iopub.execute_input":"2022-01-04T15:52:28.470273Z","iopub.status.idle":"2022-01-04T15:52:28.476537Z","shell.execute_reply.started":"2022-01-04T15:52:28.470231Z","shell.execute_reply":"2022-01-04T15:52:28.475691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy.sparse as sps\nrecommender_ItemKNNCF = ItemKNNCFRecommender(URM_train)\nrecommender_ItemKNNCF.fit(shrink=0.0, topK=200)\nrecommender_userKNN = UserKNNCFRecommender(URM_train)\nrecommender_userKNN.fit(shrink=0, topK=300)\n\nscoreshybridrecommender = ScoresHybridRecommender(URM_train, recommender_ItemKNNCF, recommender_userKNN)\n\n# x_tick = [5, 10, 50, 100, 200]\nalpha_tick = [0, 0.05, 0.1, 0.15, 0.2]\n# beta_tick = [0.1, 0.3, 0.5, 0.7, 0.9, 1]\n\nMAP_per_k = []\n\nfor alpha in alpha_tick:\n    \n    scoreshybridrecommender.fit(alpha = alpha)\n    \n    result_df, _ = evaluator_validation.evaluateRecommender(scoreshybridrecommender)\n    \n    MAP_per_k.append(result_df.loc[10][\"MAP\"])\n    print(\"alpha = {}, MAP = {}\".format(alpha, result_df.loc[10][\"MAP\"]))\n\nplt.plot(alpha_tick, MAP_per_k)\nplt.ylabel('MAP')\nplt.xlabel('TopK')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T16:49:04.304183Z","iopub.execute_input":"2022-01-04T16:49:04.304479Z","iopub.status.idle":"2022-01-04T16:53:31.68998Z","shell.execute_reply.started":"2022-01-04T16:49:04.304447Z","shell.execute_reply":"2022-01-04T16:53:31.688798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"best **alpha = 0.1**, best **MAP = 0.23448**","metadata":{}},{"cell_type":"code","source":"# Hybrid between pureSVD and user-based KNN CF\nimport scipy.sparse as sps\nrecommender_pureSVD = PureSVDRecommender(URM_train)\nrecommender_pureSVD.fit(num_factors=35)\n\nrecommender_userKNN = UserKNNCFRecommender(URM_train)\nrecommender_userKNN.fit(shrink=0, topK=300)\n\nscoreshybridrecommender = ScoresHybridRecommender(URM_train, recommender_pureSVD, recommender_userKNN)\n\n# x_tick = [5, 10, 50, 100, 200]\nalpha_tick = [0.8, 0.9, 0.95, 1]\n# beta_tick = [0.1, 0.3, 0.5, 0.7, 0.9, 1]\n\nMAP_per_k = []\n\nfor alpha in alpha_tick:\n    \n    scoreshybridrecommender.fit(alpha = alpha)\n    \n    result_df, _ = evaluator_validation.evaluateRecommender(scoreshybridrecommender)\n    \n    MAP_per_k.append(result_df.loc[10][\"MAP\"])\n    print(\"alpha = {}, MAP = {}\".format(alpha, result_df.loc[10][\"MAP\"]))\n\nplt.plot(alpha_tick, MAP_per_k)\nplt.ylabel('MAP')\nplt.xlabel('TopK')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T17:48:26.571057Z","iopub.execute_input":"2022-01-04T17:48:26.571394Z","iopub.status.idle":"2022-01-04T17:50:36.774725Z","shell.execute_reply.started":"2022-01-04T17:48:26.571361Z","shell.execute_reply":"2022-01-04T17:50:36.773647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best **alpha = 0.9**, Best **MAP = 0.2422**","metadata":{}},{"cell_type":"code","source":"# RP3beta + SLIM\nfrom Recommenders.SLIM.SLIMElasticNetRecommender import SLIMElasticNetRecommender\n\nrecommender_Slim = SLIMElasticNetRecommender(URM_train)\ntopK_tick = [5, 10, 50, 100, 200]\n# beta_tick = [0.1, 0.3, 0.5, 0.7, 0.9, 1]\n\nMAP_per_k = []\n\nfor topK in topK_tick:\n    \n    recommender_Slim.fit(l1_ratio=0.1, alpha = 1, topK=topK)\n    \n    result_df, _ = evaluator_validation.evaluateRecommender(recommender_Slim)\n    \n    MAP_per_k.append(result_df.loc[10][\"MAP\"])\n    print(\"alpha = {}, MAP = {}\".format(topK, result_df.loc[10][\"MAP\"]))\n\nplt.plot(topK_tick, MAP_per_k)\nplt.ylabel('MAP')\nplt.xlabel('TopK')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T20:09:13.032713Z","iopub.execute_input":"2022-01-04T20:09:13.033016Z","iopub.status.idle":"2022-01-04T20:09:13.065687Z","shell.execute_reply.started":"2022-01-04T20:09:13.032986Z","shell.execute_reply":"2022-01-04T20:09:13.06488Z"},"trusted":true},"execution_count":null,"outputs":[]}]}